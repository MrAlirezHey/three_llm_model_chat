{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1827370-d432-41a4-86c2-f25b5584cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import update_display, display, Markdown\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a08c9f-edb7-4787-9c9b-743197ea8ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### let's load env file for acsess to our api_keys\n",
    "load_dotenv(override=True)\n",
    "openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "#let's check Api_keys\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print('OpenAI API Key not set')\n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f6718-0a93-4cc5-97d2-219f301f70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai=OpenAI()\n",
    "claude=anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a38e2e-84ad-4a2a-acb8-3b80411b5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "###let's define our system_prompt note that you can change it by yourself also for models_name\n",
    "gpt_system=\"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "claude_system=\"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "qwem_system=\"You are a highly formal and strict chatbot. You adhere rigorously to rules and logic, prioritizing accuracy and efficiency above all else. \\\n",
    " Your responses are direct, concise, and devoid of colloquialisms or emotional expressions.\\\n",
    " If the other person deviates from the topic, is imprecise, or attempts to engage in casual conversation\\\n",
    " you firmly redirect them back to the objective at hand with an authoritative tone. You do not tolerate ambiguity or inefficiency.\"\n",
    "gpt_model=\"gpt-4o-mini\"\n",
    "claude_model=\"claude-3-haiku-20240307\"\n",
    "qwen_model='qwem3:8b'\n",
    "gpt_message=['hi there']\n",
    "claude_message=['hi']\n",
    "qwen_message=['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90791c5d-2569-47f2-a2dc-8035660ea80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_call():\n",
    "    message=[{'role':'system','content':gpt_system}]\n",
    "    for gpt,qwen,claude in zip(gpt_message,qwen_message,claude_message):\n",
    "        message.append({'role':'assistants','content':gpt})\n",
    "        message.append({'role':'user','content':'Morgan : '+claude})\n",
    "        message.append({'role':'user','content':'Alex : '+qwen})\n",
    "    response=openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=message\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f4f614b-a201-460a-86a8-ef8609b3776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def claude_call():\n",
    "    message=[]\n",
    "    for gpt,qwen,claude in zip(gpt_message,qwen_message,claude_message):\n",
    "        message.append({'role':'user','content':'Brad : '+gpt})\n",
    "        message.append({'role':'assistants','content':claude})\n",
    "        message.append({'role':'user','content':'Alex : '+qwen})\n",
    "    message.append({'role':'user','content':'Brad : '+gpt_message[-1]})\n",
    "    response=claude.messages.create(\n",
    "        model=claude_model,\n",
    "        system=claude_model,\n",
    "        max_tokens=500,\n",
    "        messages=message\n",
    "    )\n",
    "    return response.content[0].text\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5358e7-3fbc-49d8-a764-e8ef28e4432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwen_call():\n",
    "    message=[{'role':'system','content':qwem_system}]\n",
    "    for gpt,qwen,claude in zip(gpt_message,qwen_message,claude_message):\n",
    "        message.append({'role':'user','content':\"Bard : \"+ gpt})\n",
    "        message.append({'role':'user','content':'Morgan : '+claude})\n",
    "        message.append({'role':'assistants','content':+qwen})\n",
    "    message.append({'role':'user','content':\"Bard : \"+ gpt_message[-1]})\n",
    "    message.append({'role':'user','content':'Morgan : '+claude_message[-1]})\n",
    "    response=ollama.chat(model=qwen_model,messages=message)\n",
    "    return response['message']['content']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6af6c-c527-4f22-90a8-d0f5d7ac2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"GPT:\\n{gpt_message[0]}\\n\")\n",
    "print(f\"Claude:\\n{claude_message[0]}\\n\")\n",
    "print(f\"Qwen:\\n{qwen_message[0]}\\n\")\n",
    "for i in range(30):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_message.append(gpt_next)\n",
    "    \n",
    "    claude_next = call_claude()\n",
    "    print(f\"Claude:\\n{claude_next}\\n\")\n",
    "    claude_message.append(claude_next)\n",
    "\n",
    "    qwen_next=qwen_call()\n",
    "    print(f\"Qwen:\\n{qwen_next}\\n\")\n",
    "    qwen_message.append(qwen_next)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
